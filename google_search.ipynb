{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import chromadb\n",
    "import uuid\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import re\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade --quiet  langchain-google-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_CSE_ID\"] =os.getenv(\"GOOGLE_CSE_ID\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model_name=\"deepseek-r1-distill-llama-70b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke(\"who is current president of usa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "from langchain_google_community import GoogleSearchAPIWrapper\n",
    "\n",
    "search = GoogleSearchAPIWrapper()\n",
    "\n",
    "tool = Tool(\n",
    "    name=\"google_search\",\n",
    "    description=\"Search Google for recent results and give consize in 2-3 lines answer.\",\n",
    "    func=search.run,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "model = llm\n",
    "search = GoogleSearchAPIWrapper()\n",
    "tools = [search.run]\n",
    "agent_executor = create_react_agent(model, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question  =\"Hi I am dheeraj\"\n",
    "# ans=tool.run(question)\n",
    "response=llm.invoke(f\"This is recent update I have found through google search Information: {ans}, so just make it to the point and remove unnecessary for this question:{question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sep 30, 2024 ... I'm Dheeraj from Chennai, India. I've been admitted into L&S this fall. I figured I'll major in economics because I love gambling. Oct 19, 2021 ... 27 votes, 69 comments. Hey Reddit, it's Dheeraj. As developers ourselves, Manoj (DevRev co-founder) and I realized there are a lot of\\xa0... Nov 16, 2023 ... I'm a photographer, filmmaker and a digital artist based in India. My work revolves around cityscapes and landscapes. I love architecture, symmetry, color and\\xa0... Mar 17, 2016 ... 3.9K votes, 373 comments. Hi Reddit! My research is about what happens to our memories when we cannot remember. When we experience memory\\xa0... Aug 27, 2024 ... Hi Dheeraj,. thanks a lot for the additional tests. I am a little lost myself right now to be honest. Have you tried changing the supply\\xa0... Jan 31, 2023 ... Hello @Dheeraj,. I am glad this is working now! Thank you @mitchell ... Hi. I'm trying to update multiple columns on the board using. let\\xa0... Sep 27, 2017 ... Hi,I am doing DWG to DWG translation filtering only points using ... Hi @dheeraj,. Please, see the attached and tell me if your good for\\xa0... Backend Engineer things at Marvin Â· Hello there! I am an Engineer in love with backend systems & web-dev. I'm always building, developing, fixing,\\xa0... About Me. Hi, there! I'm Dhiraj, a Computer Science Grad Student, Researcher, and Developer. My active area of interest and expertise is Machine Learning\\xa0... Apr 15, 2020 ... My Facebook page, Facebook profile and my Instagram account was hacked. We just recovered it yesterday (14th April 2020) after filing an official complain to\\xa0...\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to figure out how to help this user. They provided a bunch of information from a Google search about someone named Dheeraj. It looks like they\\'re trying to get a concise version of this information for a question. The user wrote \"Hi I am dheeraj\" and wants it to the point without unnecessary details.\\n\\nFirst, I should go through each of the points they provided. There\\'s a lot here, so I need to pick out the key details. Let\\'s see:\\n\\n- Admitted to L&S, majoring in economics because he loves gambling.\\n- Co-founder of DevRev with Manoj, mentioned on Reddit.\\n- Photographer, filmmaker, digital artist based in India, into cityscapes, architecture, symmetry, color.\\n- Research on memory, with a Reddit post about it.\\n- Some technical discussions about tests and updating columns.\\n- Backend engineer at Marvin, loves backend systems and web-dev.\\n- Computer Science grad student, researcher, developer with expertise in Machine Learning.\\n- Hacked Facebook and Instagram accounts, recovered after filing a complaint.\\n\\nHmm, that\\'s a lot. The user wants it concise, so I should focus on the main points without the extra details. Maybe start with his name, what he does, his interests, and any notable achievements or roles.\\n\\nWait, but some of these points might be from different people named Dheeraj. The user might be compiling information about himself or someone else. I need to make sure I\\'m not mixing up different individuals. For example, the photographer and the backend engineer might be different people.\\n\\nBut the user seems to be presenting all this as information about one person, so I\\'ll proceed under that assumption. I\\'ll highlight his admission to L&S, majoring in economics, his role as a co-founder, his work in photography and digital arts, his research interests, technical skills, and the hacking incident.\\n\\nI should structure it in a way that flows well, starting with his introduction, then education, career, interests, and any other relevant info. Keep each point brief and to the point.\\n\\nLet me try to draft it:\\n\\n\"Hi, I\\'m Dheeraj. I\\'m currently a student at L&S, majoring in economics. I\\'m the co-founder of DevRev and have a strong interest in photography, filmmaking, and digital art, focusing on cityscapes and architecture. I also conduct research on memory and its implications. Professionally, I work as a backend engineer with a passion for web development. Additionally, I\\'m a Computer Science grad student with expertise in Machine Learning. I recently recovered my social media accounts after a hacking incident.\"\\n\\nWait, that seems a bit too much. Maybe I can make it more concise by combining some points. For example, mentioning both his studies and work together.\\n\\nAlternatively, perhaps the user just wants a short introduction without all the details. So maybe:\\n\\n\"Hi, I\\'m Dheeraj. I\\'m a student at L&S, majoring in economics, and I\\'m passionate about photography, filmmaking, and digital art. I also work as a backend engineer and am interested in Machine Learning.\"\\n\\nThat covers the main points without getting too detailed. I think that\\'s concise and to the point, as the user requested.\\n</think>\\n\\nHi, I\\'m Dheeraj. I\\'m a student at L&S, majoring in economics, and I\\'m passionate about photography, filmmaking, and digital art. I also work as a backend engineer and am interested in Machine Learning.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " \"Hi, I'm Dheeraj. I'm a student at L&S, majoring in economics, and I'm passionate about photography, filmmaking, and digital art. I also work as a backend engineer and am interested in Machine Learning.\"]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cresponse=re.sub(r\"<think>.*?</think>\", \"\", response.content, flags=re.DOTALL).split(\"\\n\")\n",
    "cresponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool.run(\"who is current president of usa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "who is the president of usa\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  run (call_g4d2)\n",
      " Call ID: call_g4d2\n",
      "  Args:\n",
      "    query: president of USA\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: run\n",
      "\n",
      "America Is Back Â· Donald J. Trump. President of the United States Â· JD Vance. VICE PRESIDENT OF THE UNITED STATES Â· Melania Trump. First Lady OF THE UNITED STATES. The president is one of the world's most powerful political figures and the leader of the world's only remaining superpower. 45th & 47th President of the United States. The Golden Age of America Begins Right Now. Donald J. Trump serves as the 47th President of the United States. He also served as the 45th. Read the President's full biography. 16M Followers, 3 Following, 83 Posts - President Donald J. Trump (@potus) on Instagram: \"45th & 47th President of the United States. U.S. Presidents ; George Washington. 1 Â· 1789. 1797 ; John Adams. 2 Â· 1797. 1801 ; Thomas Jefferson. 3 Â· 1801. 1809 ; James Madison. 4 Â· 1809. 1817 ; James Monroe. 5. 50th Vice President of the United States. Christian, husband, father. Proud to serve the American people with President Donald J. Trump. Find out how a candidate becomes president of the United States. Learn about caucuses and primaries, political conventions, the Electoral College, and more. \"Let us be ambitious. Let us be bold. Let us move forward, together, as the Flagship of the Gulf Coast.\". Sep 20, 2024 ... The US Constitution and the Presidential Succession Act of 1947 outline the presidential order of succession.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The current President of the United States is **Joe Biden**. He was inaugurated on January 20, 2021, and is serving his term as the 46th President of the United States. \n",
      "\n",
      "The discrepancy in the tool's output appears to be incorrect, as Donald Trump served as the 45th President before Joe Biden. For the most accurate and up-to-date information, please refer to reliable news sources or official government websites.\n"
     ]
    }
   ],
   "source": [
    "# Use the agent\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "for step in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"who is the president of usa\")]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []\n",
    "tool_node = ToolNode(tools)\n",
    "model = llm\n",
    "bound_model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "    # This is a placeholder for the actual implementation\n",
    "    # Don't let the LLM know this though ð\n",
    "    return \"It's sunny in San Francisco, but you better look out if you're a Gemini ð.\"\n",
    "def should_continue(state: MessagesState):\n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    # If there is no function call, then we finish\n",
    "    if not last_message.tool_calls:\n",
    "        return END\n",
    "    # Otherwise if there is, we continue\n",
    "    return \"action\"\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = bound_model.invoke(state[\"messages\"])\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new graph\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    "    # Next, we pass in the path map - all the possible nodes this edge could go to\n",
    "    [\"action\", END],\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you remember my name?\n",
      "\n",
      "\n",
      "Yes, I remember! You mentioned your name is Dheeraj. How can I assist you today? ð\n"
     ]
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "query=\"do you remember my name?\"\n",
    "\n",
    "input_message = HumanMessage(content=f\"{query}\")\n",
    "for event in app.stream({\"messages\": [query]}, config, stream_mode=\"values\"):\n",
    "    cleaned_response = re.sub(r\"<think>.*?</think>\", \"\", event[\"messages\"][-1].content, flags=re.DOTALL)\n",
    "    print(cleaned_response)\n",
    "    # event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cleaned_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hey ,how are you\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hey! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you with whatever you need. How are *you* doing? ð\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am dheeraj \n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Alright, the user just said, \"I am dheeraj.\" So, he's introducing himself. I should respond in a friendly and welcoming manner. Maybe start with a greeting and ask how I can assist him today. Keeping it open-ended encourages him to share what he needs help with. I want to make sure he feels comfortable asking for anything. Let's keep the tone warm and approachable.\n",
      "</think>\n",
      "\n",
      "Hello, Dheeraj! Welcome. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "\n",
      "Hello, Dheeraj! Welcome. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what first question i have asked\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "\n",
      "Your first question was \"hey ,how are you\".\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "\n",
      "\n",
      "Your first question was \"hey ,how are you\".\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    query=input(\"inter your text\")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    input_message = HumanMessage(content=f\"{query}\")\n",
    "    for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
